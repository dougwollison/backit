#!/usr/bin/env python3
import os
import sys
import gc
import tarfile
import shutil
import hashlib
from glob import glob
from api import B2
from shared import config, project, option as backup

tarballs_dir = os.path.realpath( config.get( 'storage', 'tarballs_dir' ) )
backup_dir = os.path.realpath( config.get( 'rsync', 'target_base' ) )
part_size = int( config.get( 'backblaze', 'part_size' ) )
account_id = config.get( 'backblaze', 'account_id' )
account_key = config.get( 'backblaze', 'account_key' )
bucket = config.get( 'backblaze', 'bucket' )

parent_folder = config.get( 'backblaze', 'parent_folder', fallback='' )
separate_folders = config.get( 'backblaze', 'separate_folders', fallback=False )

flag_file = '/tmp/backit-%s-' % project

# Get the specified or otherwise latest backup
if backup :
	archive_dir = backup_dir + '/' + str( backup )
else :
	archive_dir = sorted( glob( backup_dir + '/20*_*' ), reverse=True )[0]

if not os.path.isdir( archive_dir ) :
	print( 'Archive not found: ' + archive_dir )
	sys.exit()

print( 'Exporting %s to B2...' % archive_dir )

api = B2( account_id, account_key, part_size )

def mkdir( dir ) :
	"""Shorthand for creating a directory that doesn't exist yet"""

	if not os.path.exists( dir ) :
		os.makedirs( dir )

	return dir

mkdir( tarballs_dir )

def make_archive( folder, parent = '' ) :
	"""Create a gzipped tarball of the folder and upload it to B2"""

	basename = os.path.basename( folder );
	b2_filename = parent_folder + '/' + os.path.basename( parent ) + '/' + basename + '.tgz'
	tar_file = tarballs_dir + '/' + b2_filename
	tar_dir = os.path.dirname( tar_file )

	# These files will flag the status of the file
	hash = hashlib.md5( tar_file.encode( 'utf-8' ) ).hexdigest()
	ready_flag = flag_file + hash + '.ready';
	done_flag = flag_file + hash + '.done';

	# If straight up done, skip
	if os.path.isfile( done_flag ) :
		print( 'Skipping ' + folder )
		return

	mkdir( tar_dir )

	# (Re)create the archive if not yet ready
	if not os.path.isfile( ready_flag ) :
		print( 'Archiving ' + folder + '...' )

		tar = tarfile.open( tar_file, 'w:gz' )
		tar.add( folder, arcname = basename )
		tar.close()

		# Paranoid cleanup
		del tar
		gc.collect()

		# Flag as ready
		open( ready_flag, 'a' ).close()

		print( 'Done.' )

	print( 'Uploading ' + tar_file + '...' )

	# Upload to B2
	api.upload( tar_file, bucket, b2_filename )

	print( 'Done.' )

	print( 'Cleaning up...' )

	# Remove the tar file and ready flag
	os.remove( tar_file )
	os.remove( ready_flag )

	# Flag as done
	open( done_flag, 'a' ).close()

	print( 'Done.' )

# Flag as being in the process of archiving
hash = hashlib.md5( archive_dir.encode( 'utf-8' ) ).hexdigest()
archiving_flag = '/tmp/backit-%s-%s.archiving' % ( project, hash )
open( archiving_flag, 'a' ).close()

if separate_folders :
	folders = separate_folders.split( ':' )

	for folder in folders :
		folder = archive_dir + folder

		for dir in sorted( glob( folder ) ) :
			make_archive( dir, archive_dir )

else :
	make_archive( archive_dir )

shutil.rmtree( tarballs_dir )

for done_flag in glob( '/tmp/backit-%s-*.done' % project ) :
	os.remove( done_flag )

os.remove( archiving_flag )
