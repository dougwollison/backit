#!/usr/bin/env python3
import os
import sys
import gc
import tarfile
import shutil
from glob import glob

from api import B2
import shared as backit
from shared import option as date
import flags

tarballs_dir = os.path.realpath( backit.get( 'storage', 'tarballs_dir' ) )
backups_root = os.path.realpath( backit.get( 'rsync', 'backups_root' ) )
part_size = int( backit.get( 'backblaze', 'part_size' ) )
account_id = backit.get( 'backblaze', 'account_id' )
account_key = backit.get( 'backblaze', 'account_key' )
bucket = backit.get( 'backblaze', 'bucket' )

parent_folder = backit.get( 'backblaze', 'parent_folder', '' )
separate_folders = backit.get( 'backblaze', 'separate_folders', False )

# Get the specified or otherwise latest backup
if date :
	print( backups_root, date )
	backup_dir = backit.pathit( backups_root, date )
else :
	backup_dir = sorted( glob( backups_root + '/20*_*' ), reverse=True )[0]

# Ensure the archive exists
if not os.path.isdir( backup_dir ) :
	print( 'Archive not found: ' + backup_dir )
	sys.exit()

# Check if the backup_dir is somehow still downloading
if flags.check( backup_dir, 'downloading' ) :
	print( 'Unable to archive ' + backup_dir + ' (download in progress).' )
	sys.exit( 0 )

print( 'Exporting %s to B2...' % backup_dir )

api = B2( account_id, account_key, part_size )

def mkdir( dir ) :
	"""Shorthand for creating a directory that doesn't exist yet"""

	if not os.path.exists( dir ) :
		os.makedirs( dir )

	return dir

mkdir( tarballs_dir )

def make_archive( folder, parent = '' ) :
	"""Create a gzipped tarball of the folder and upload it to B2"""

	basename = os.path.basename( folder );
	b2_filename = backit.pathit( parent_folder, os.path.basename( parent ), basename + '.tgz' )
	tar_file = backit.pathit( tarballs_dir, b2_filename )
	tar_dir = os.path.dirname( tar_file )

	# If straight up done, skip
	if flags.check( tar_file, 'done' ) :
		print( 'Skipping ' + folder )
		return

	mkdir( tar_dir )

	# (Re)create the archive if not yet ready
	if not flags.check( tar_file, 'ready' ) :
		print( 'Archiving ' + folder + '...' )

		tar = tarfile.open( tar_file, 'w:gz' )
		tar.add( folder, arcname = basename )
		tar.close()

		# Paranoid cleanup
		del tar
		gc.collect()

		# Flag as ready
		flags.write( tar_file, 'ready' )

		print( 'Done.' )

	print( 'Uploading ' + tar_file + '...' )

	# Upload to B2
	api.upload( tar_file, bucket, b2_filename )

	print( 'Done.' )

	print( 'Cleaning up...' )

	# Remove the tar file
	os.remove( tar_file )

	# Flag as done
	flags.remove( tar_file, 'done' )

	print( 'Done.' )

# Flag as being in the process of archiving
flags.write( backup_dir, 'archiving' )

if separate_folders :
	folders = separate_folders.split( ':' )

	print( folders )

	for folder in folders :
		folder = backit.pathit( backup_dir, folder )

		for dir in sorted( glob( folder ) ) :
			make_archive( dir, backup_dir )

else :
	make_archive( backup_dir )

shutil.rmtree( tarballs_dir )

for done_flag in glob( '/tmp/backit-%s-*.done' % backit.project ) :
	os.remove( done_flag )

flags.remove( backup_dir, 'archiving' )
